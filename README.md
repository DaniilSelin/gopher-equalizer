# gopher-equalizer
## Описание проекта

gopher-equalizer — это обратный HTTP-прокси на Go, обеспечивающий балансировку нагрузки между несколькими экземплярами бэкенд-сервисов. Проект принимает входящие запросы и распределяет их равномерно между рабочими узлами, защищая систему от перегрузок. Для ограничения частоты запросов используется алгоритм «токен-бакета» (token bucket). перед запуском стоит посмотреть конфигурацию config/config.yml

## Архитектура проекта

### Диаграмма пакетов

![gopher-equalizer drawio](https://github.com/user-attachments/assets/8b109d85-462f-4bc3-801d-f0459018fb74)

#### Описание

    1. main - Точка входа приложения. Загружает конфиг, инициализирует логгер, БД, репозитории, сервисный     слой, маршрутизатор API и прокси. Запускает одновременно HTTP-API, прокси и фоновый health-checker.

    2. config — Отвечает за загрузку config.yml в структуру Config. Все остальные пакеты (main, balancer, proxy, service, repository, healthChecker, logger) получают *config.Config и читают из него свои параметры.

    3. logger — Инициализирует контекстный логгер. Сам логгер реализован на основе zap.Logger и хранится в контекст. Предоставляет функцию GetLoggerFromCtx для извлечения логгера из контекста.

    4. interfaces — Содержит набор общих интерфейсов:
        type IBucketRepository  // Create/Get/Update/Delete для token buckets  
        type IBucketService     // бизнес-логика лимитера + CRUD  
        type IBalancer          // NextBackend, ResetBackends  
        type IStrategy          // Next, ResetBackends
    Этот пает служит для связи пакетов между собой. Если слою требуется методы из другого слоя, то супертип слоя должен содержать в себе поля с интерфейсом необходимого типа с этими методами.
    
    5. models & errdefs — models: определяет сущность Bucket. errdefs: централизованный пакет ошибок, который возвращают репозиторий и сервис, а API/прокси превращают их в HTTP-коды. Хранит в себе станадртные ошибки общие дя всего балансировщика.

    6. repository — Реализует IBucketRepository через PostgreSQL (pgxpool). Миграции лежат в internal/database/migrations, таблица token_buckets.

    7. service — Реализует IBucketService: основная бизнес-логика token bucket, пополнение и потребление токенов, а так же CRUD опрации

    8. balancer — Обёртка над IStrategy. Balancer держит стратегию (RoundRobin и т.п.) и делегирует ей выбор следующего бэкенда. Позволяет сбрасывать пул серверов (ResetBackends) для health-checker’а.

    9. pkg/strategies — Стратегии балансировки: roundrobin.go, random.go и др. Помещен в именно этот пакет, так как код вполне переиспользуемый, и заменяемый. Тут можно реализовать другой алгоритм балансировки, главное соответствовать интерфейсу: IStrategy.

    10. transport/http
    
        api: маршруты для CRUD-API бакетов.
    
        proxy: ReverseProxy, который делает rate-limit и балансировку.
    
        healthCheck: фоновый проверяющий компонент, который пингует бэкенды.



### Прокси с балансировщиком

Компонент Proxy принимает HTTP-запросы клиентов и перенаправляет их к бэкенд-сервисам. Для распределения нагрузки применяться алгоритм Round Robin, при котором запросы циклично идут по списку серверов. Можно реализовать и свой алгоритм балансировки нагрузки:

 1. Добавить реалиацию в pkg/strategies, которая удовлетворяет интерфейсу IStrategy
 2. Исравить мапу strategyFactories в internal/balancer/strategies.go, добаив функцию стратегии.
 3. Указать ключ для strategyFactories в конфигурации - 

        balancer:
          strategy: your_strategies

Изначально хотел релизовать что то похожее на паттерн plugin, но в итоге получилась больше стратегия нежели он.

### API для работы с бакетами

Сервис предоставляет REST API для управления «бакетами». Поддерживаются операции создания, получения списка и удаления бакетов. Данные при этом передаются в формате JSON.

#### Эндпоинты

POST /buckets

Создание нового bucket'а.

Request JSON:

    {
      "client_id": "string",
      "capacity": 100,
      "tokens": 50
    }

Response:

    201 Created — bucket успешно создан.

    400 Bad Request — неверный JSON или данные.

    409	Conflict — clientID уже занят

    500	Internal — ошибка на стороне сервера

GET /buckets

Список всех bucket'ов.

Query параметры:

    limit — количество (по умолчанию из конфига).

    offset — смещение (по умолчанию 0).

Response:

    200 OK — массив bucket'ов.
    
    500	Internal — ошибка на стороне сервера

GET /buckets/{id}

Получение информации о конкретном bucket'е.

Response:

    200 OK — данные bucket'а.

    404 Not Found — не найден.

    500	Internal — ошибка на стороне сервера

PUT /buckets/{id}

Изменение capacity bucket'а.

Request JSON:

    {
      "client_id": "string",
      "capacity": 200
    }

Response:

    204 No Content — обновлено.

    400 Bad Request — ошибка ввода.

    404 Not Found — bucket не найден.

    500	Internal — ошибка на стороне сервера

PATCH /buckets/{id}

Изменение количества tokens в bucket'е.

Request JSON:

    {
      "client_id": "string",
      "tokens": 100
    }

Response:

    204 No Content — обновлено.

    400 Bad Request — ошибка ввода.

    404 Not Found — bucket не найден.

    500	Internal — ошибка на стороне сервера

DELETE /buckets/{id}

Удаление bucket'а.

Response:

    204 No Content — удалено.

    404 Not Found — не найден.

    500	Internal — ошибка на стороне сервера

### Здоровье бэкендов (health-checker)

Компонент проверки здоровья периодически опрашивает бэкенд-сервисы  и обновляет их статус. При обнаружении недоступности сервис помечается как «down», и прокси больше не отправляет на него запросы. Как только сервер вновь станет доуступен, health-checker пометит его как живым. Список backend серверов указывается в конфигурации - 
    
    balancer:
      strategy: round_robin # round_robin, random 
      backends:
        - http://localhost:8081
        - http://localhost:8082
        - http://localhost:8083

### Конфигурация и логгер

Настройки приложения хранятся в YAML-файле config/config.yml и загружаются при старте сервиса. В конфигурации указываются параметры подключения к PostgreSQL (host, port, user, password, dbname), порт сервера, список URL бэкендов, интервалы проверки здоровья, ограничения скорости, а также уровень логирования (например, info, debug и т.д.).

## Запуск

### Запуск через Docker Compose

Перед запуском стоит посмотреть в конфигурацию и build/docker-compose.yml. 
Выполните команду в корне проекта:

    docker-compose -f build/docker-compose.yml up --build

Это создаст и запустит контейнеры (PostgreSQL и сам сервис). После успешного старта API будет доступно по указанному в конфиге порту (http://localhost:8080).

### Локальный запуск (без Docker)

Склонируйте репозиторий и перейдите в каталог проекта.

Установите зависимости:

    go mod tidy

Запустите PostgreSQL локально и создайте базу данных, параметры которой указаны в config/config.yml. Например:

    psql -U postgres -c "CREATE DATABASE gopher_equalizer;"

Проверьте и при необходимости отредактируйте настройки в config/config.yml (адрес БД, имя базы, порт сервера, список бэкендов и т.д.).

Запустите сервис:

    go run cmd/main.go

После запуска сервис будет слушать указанный в конфиге порт.

## Работа с базой данных

В проекте фигурирует только одна DTO/бизнес сущность - Bucket. В бд она хранится как token_buckets.
В ней есть три ограничения целостности - capacity > 0, tokens >= 0, tokens <= capacity, так же индекс для ускорения запросов по времени изменения, на случай, если потребуется keyset-плагинация. Помимо этого, имеется триггер на обновление времени при измениении количества токенов.

## Завершение работы

Реализован механизм  Gracefull Shutdown, достаточно отпавить сигнал -

    kill -SIGINT  $(lsof -ti:<номер-порта-сервера>)

## Тестирование

Я покрыл тестами (не производительности) repository и serivce. Тесты находятся в тех же слоях, которые и тестируют.
Так же я провел нагрузочное тестирование -
![image](https://github.com/user-attachments/assets/e0ae4e7d-cfc3-43a8-8e47-422c81500c2d)

Многие запросы получили в качестве ответа 500, т.к. токены были быстро потрачены. В среднем прокси обрабатывает 7992.30 запросов в секунду.

Так же воспользовался Apache Bench для проверки моего балансироващика - 

![image](https://github.com/user-attachments/assets/dd948cec-91b9-4465-bbf1-0ece61f3b869)

Тут я уже самостоятельно выстаивл для "client_id":"::1"? capacity в 1000 и выдал соответствующее число токенов через PATCH и PUT запросы на http://localhost:8080/buckets/::1. Картина сложилась такая - 383.66 запросов/сек, что довольно мало. Есть подозрения на медленную работу базы данных. Думаю ситуацию можно исправить кешируя bucket по clientID, что избавило бы от лишнего обращения к бд в TryConsume пакета service.

### Вопросы для разогрева

1) Самой интересной задачей в программировании для меня стала командная разработка в рамках курса Яндекс Лицея платформы для голосований. В команде я был в качестве лида, поэтому архитектуру придумывал я, задачи раскидывал я, проверял выолненные задачи тоже я. Очень сложно было конролировать сразу 4 человека (в том числе себя), следить за дедлайнами спринтов. Разработка сопровождалась постоянными тех-долгами, сложно было обьяснить незнакомым мне людям, что именно от них требуется. Работли в Trello и GitLab. Сложно было рефакторить код за некоторыми людьми, так как зачастую было сложно разобраться, что именно они написали и как у них оно работает. С задачей справились за 3 недели, выполнив план-минимум.

2) Своим самым большим факапом считаю выбор в качестве первого языка программирования Python. Язык не самый походящий для изучения програмиирования, ситуация исправилась с моим поступлением в ВУЗ, где меня обучили C, а в скоре и С++. C мне понравился больше, и на нем я писал некоторое время, вскоре перешел на Go. Golang на данный момент мой любимый язык программирования

3) Ожидаю, помимо интересных задач, возможность поработать в команде профессионалов, закрыть свои первые таски, получить код-ревью от опытных разработчиков.

P.S. Перед последним пушем забыл пройтись по коду go fmt, пушить после того как отправил решение побоялся.
